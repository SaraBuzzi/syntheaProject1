{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SELECT-FROM-WHERE-GROUP BY-HAVING\n",
   "id": "3d6dffb8505993df"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:40.802984Z",
     "start_time": "2025-09-05T16:18:40.479353Z"
    }
   },
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Set, Dict, List, Tuple, Any, Optional\n",
    "import os, uuid\n",
    "\n",
    "from sqlalchemy.orm.base import PASSIVE_OFF"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:19:12.520571Z",
     "start_time": "2025-09-05T16:19:12.482767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "USER = \"postgres\"\n",
    "HOST = \"localhost\"\n",
    "PORT = \"5432\"\n",
    "PASSWORD = \"user\"\n",
    "\n",
    "DB_ADMIN_URL = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/postgres\"\n",
    "engine_admin = create_engine(DB_ADMIN_URL, isolation_level=\"AUTOCOMMIT\")\n",
    "\n",
    "DB_URL = f\"postgresql+psycopg2://{USER}:{PASSWORD}@{HOST}:{PORT}/synthea\"\n",
    "engine = create_engine(DB_URL)\n",
    "print(\"Connesso al database synthea\")"
   ],
   "id": "2a7b91cb3b50f26f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connesso al database synthea\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:53.524413Z",
     "start_time": "2025-09-05T16:18:53.517953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run(sql_or_text, show=False):\n",
    "    with engine.begin() as conn:\n",
    "        stmt = text(sql_or_text) if isinstance(sql_or_text, str) else sql_or_text\n",
    "        result = conn.execute(stmt)\n",
    "        if result.returns_rows:\n",
    "            df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "            if show:\n",
    "                display(df)\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "\n",
    "def _strip_semicolon(sql: str) -> str:\n",
    "    return re.sub(r';\\s*$', '', sql.strip())\n",
    "\n",
    "\n",
    "def _count_table(tname: str) -> int:\n",
    "    return int(run(f\"SELECT COUNT(*) AS n FROM {tname};\").iloc[0][\"n\"])\n",
    "\n",
    "\n",
    "def _size_table(tname: str) -> int:\n",
    "    return int(run(f\"SELECT pg_total_relation_size('{tname}') AS bytes;\").iloc[0][\"bytes\"])\n",
    "\n",
    "\n",
    "def _network_bytes(strategy_key: str, sizes: dict) -> int:\n",
    "    if strategy_key == \"owner-server\":\n",
    "        return sizes.get(\"ro\", 0) + sizes.get(\"rs\", 0)\n",
    "    if strategy_key == \"server-owner\":\n",
    "        return sizes.get(\"rs\", 0)\n",
    "    if strategy_key == \"owner-only\":\n",
    "        return 0\n",
    "    if strategy_key == \"server-only\":\n",
    "        return sizes.get(\"out\", 0)\n",
    "    if strategy_key == \"parallel\":\n",
    "        return sizes.get(\"ro\", 0) + sizes.get(\"rs\", 0)\n",
    "    return 0\n",
    "\n",
    "def _split_outside_parents(s: str) -> list[str]:\n",
    "    items, buf, depth = [], [], 0\n",
    "    for ch in s:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth = max(0, depth - 1)\n",
    "        if ch == ',' and depth == 0:\n",
    "            items.append(''.join(buf).strip())\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(ch)\n",
    "    if buf:\n",
    "        items.append(''.join(buf).strip())\n",
    "    return items\n",
    "\n",
    "def _unqualify(tok: str) -> str:\n",
    "    t = tok.strip().strip('\"').strip()\n",
    "    t = t.split()[0]\n",
    "    if '.' in t:\n",
    "        t = t.split('.')[-1]\n",
    "    return t.lower()\n",
    "\n",
    "\n"
   ],
   "id": "15c3709a1f49f18",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "FRAMMENTAZIONE VERTICALE\n",
    "\n",
    "# PATIENTS\n",
    "Owner(PATIENTS) = { id, birthdate,ssn, drivers, passport, first, middle, last, maiden, address, city, fips, zip, lat, lon, income }\n",
    "\n",
    "\n",
    "Server(PATIENTS) = { id, deathdate, gender, race, ethnicity, marital, prefix, suffix, birthplace, state, county, healthcare_expanses, healthcare_coverage}"
   ],
   "id": "22ae5ea94b5bb117"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:47:58.430797Z",
     "start_time": "2025-08-28T08:47:58.369605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# se servisse ricaricare i dati\n",
    "\n",
    "sql = open(\"fragmentPatients.sql\").read()\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    if sql.strip():\n",
    "        conn.execute(text(sql))\n",
    "        print(\"Frammentazione creata\")\n",
    "    else:\n",
    "        print(\"Errore\")\n",
    "\n",
    "# O semplicemente uso la funzione run(sql)"
   ],
   "id": "2c547a7fbc9ece51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frammentazione creata\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T16:29:08.867179Z",
     "start_time": "2025-08-28T16:29:08.813117Z"
    }
   },
   "cell_type": "code",
   "source": "run(''' ANALYZE owner.patients_owner; ANALYZE server.patients_server;''')",
   "id": "3acbe9d03e7b0f90",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:56.105569Z",
     "start_time": "2025-09-05T16:18:56.102821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Fo = {\n",
    "    \"id\", \"birthdate\", \"ssn\", \"drivers\", \"passport\",\n",
    "    \"first\", \"middle\", \"last\", \"maiden\",\n",
    "    \"address\", \"city\", \"fips\", \"zip\", \"lat\", \"lon\",\n",
    "    \"income\"\n",
    "}\n",
    "\n",
    "Fs = {\n",
    "    \"id\", \"deathdate\", \"gender\", \"race\", \"ethnicity\", \"marital\",\n",
    "    \"prefix\", \"suffix\", \"birthplace\", \"state\", \"county\",\n",
    "    \"healthcare_expenses\", \"healthcare_coverage\"\n",
    "}\n"
   ],
   "id": "10fc3c1a080d2502",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:58.039008Z",
     "start_time": "2025-09-05T16:18:58.029559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_query_groupby(query: str) -> Tuple[Set[str], Set[str], List[Dict[str, Any]], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Caso 3: GROUP BY + (opzionale) HAVING, senza WHERE.\n",
    "    Estrae:\n",
    "      - colonne plain (non aggregate) dal SELECT\n",
    "      - colonne del GROUP BY\n",
    "      - lista delle aggregazioni (count/sum/avg/min/max)\n",
    "      - testo grezzo della clausola HAVING (se presente), altrimenti None\n",
    "    \"\"\"\n",
    "    q = query.strip()\n",
    "\n",
    "    # SELECT ... FROM ...\n",
    "    m_sel = re.search(r\"\\bselect\\s+(.*?)\\s+from\\b\", q, re.I | re.S)\n",
    "    if not m_sel:\n",
    "        raise ValueError(\"SELECT ... FROM mancante.\")\n",
    "    sel_txt = m_sel.group(1)\n",
    "    rest = q[m_sel.end():]\n",
    "\n",
    "    # GROUP BY ...\n",
    "    m_gb = re.search(r\"\\bgroup\\s+by\\b\", rest, re.I)\n",
    "    group_by_txt = None\n",
    "    having_txt = None\n",
    "\n",
    "    if m_gb:\n",
    "        after_gb = rest[m_gb.end():].strip()\n",
    "\n",
    "        # split semplice tra GROUP BY ... e (opzionale) HAVING ...\n",
    "        m_having = re.search(r\"\\bhaving\\b\", after_gb, re.I)\n",
    "        if m_having:\n",
    "            group_by_txt = after_gb[:m_having.start()].strip()\n",
    "            having_txt = after_gb[m_having.end():].strip()\n",
    "        else:\n",
    "            group_by_txt = after_gb\n",
    "\n",
    "        # pulizia finale del punto e virgola (se presente)\n",
    "        if group_by_txt:\n",
    "            group_by_txt = re.sub(r';\\s*$', '', group_by_txt, flags=re.S)\n",
    "        if having_txt:\n",
    "            having_txt = re.sub(r';\\s*$', '', having_txt, flags=re.S)\n",
    "\n",
    "    # SELECT: separo plain vs aggregazioni\n",
    "    select_items = _split_outside_parents(sel_txt)\n",
    "    select_plain: Set[str] = set()\n",
    "    aggs: List[Dict[str, Any]] = []\n",
    "\n",
    "    agg_re = re.compile(\n",
    "        r\"^(count|sum|avg|min|max)\\s*\\(\\s*(distinct\\s+)?(\\*|[a-zA-Z_][\\w\\.]*)\\s*\\)\\s*(?:as\\s+([a-zA-Z_]\\w*))?$\",\n",
    "        re.I\n",
    "    )\n",
    "    for it in select_items:\n",
    "        it_norm = it.strip()\n",
    "        m = agg_re.match(it_norm)\n",
    "        if m:\n",
    "            func = m.group(1).lower()\n",
    "            distinct = bool(m.group(2))\n",
    "            arg_raw = m.group(3)\n",
    "            alias = m.group(4).lower() if m.group(4) else None\n",
    "            arg = None if arg_raw == '*' else _unqualify(arg_raw)\n",
    "            aggs.append({\"func\": func, \"arg\": arg, \"distinct\": distinct, \"alias\": alias})\n",
    "        else:\n",
    "            # Colonne non aggregate (devono stare nel GROUP BY)\n",
    "            select_plain.add(_unqualify(it_norm))\n",
    "\n",
    "    group_by: Set[str] = set()\n",
    "    if group_by_txt:\n",
    "        cols = [tok for tok in _split_outside_parents(group_by_txt) if tok.strip()]\n",
    "        group_by = {_unqualify(c) for c in cols}\n",
    "\n",
    "    # Coerenza: i \"plain\" devono essere tutti nel GROUP BY (come nel tuo caso 2)\n",
    "    if select_plain - group_by:\n",
    "        missing = \", \".join(sorted(select_plain - group_by))\n",
    "        raise ValueError(f\"Le colonne non aggregate in SELECT devono apparire nel GROUP BY (manca: {missing}).\")\n",
    "\n",
    "    return select_plain, group_by, aggs, having_txt\n",
    "\n",
    "\n",
    "def classify_groupby_agg(group_by: Set[str], aggs: List[Dict[str, Any]],\n",
    "                         Fo: Set[str], Fs: Set[str]) -> Dict[str, Set[str]]:\n",
    "    \"\"\"\n",
    "    Invariante: nessuna WHERE. Mi basta sapere dove stanno i G e gli arg delle funzioni.\n",
    "    Nota: COUNT(*) ha arg=None -> non è assegnato a nessun lato.\n",
    "    \"\"\"\n",
    "    G_owner = {g for g in group_by if g in Fo}\n",
    "    G_server = {g for g in group_by if g in Fs}\n",
    "    Agg_owner = {a[\"arg\"] for a in aggs if a.get(\"arg\") and a[\"arg\"] in Fo}\n",
    "    Agg_server = {a[\"arg\"] for a in aggs if a.get(\"arg\") and a[\"arg\"] in Fs}\n",
    "    return {\n",
    "        \"G_owner\": G_owner, \"G_server\": G_server,\n",
    "        \"Agg_owner\": Agg_owner, \"Agg_server\": Agg_server,\n",
    "    }\n",
    "\n",
    "\n",
    "def choose_strategy_groupby(classified: Dict[str, Set[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Caso 2: GROUP BY senza WHERE.\n",
    "\n",
    "    Regole:\n",
    "      - owner-only:   G ⊆ Fo e tutti gli arg di agg (se presenti) in Fo\n",
    "      - server-only:  G ⊆ Fs e tutti gli arg di agg (se presenti) in Fs\n",
    "      - server-owner: G ⊆ Fo e almeno un arg di agg in Fs (nessun arg in Fo)\n",
    "      - owner-server: G ⊆ Fs e almeno un arg di agg in Fo (nessun arg in Fs)\n",
    "      - parallel:     G spezzato tra i due oppure arg distribuiti su entrambi\n",
    "      Nota: COUNT(*) ha arg=None → non forza alcun lato.\n",
    "      Nota: HAVING non influisce sulla scelta (si applica dopo il GROUP BY).\n",
    "    \"\"\"\n",
    "    G_o, G_s = classified[\"G_owner\"], classified[\"G_server\"]\n",
    "    A_o, A_s = classified[\"Agg_owner\"], classified[\"Agg_server\"]\n",
    "\n",
    "    # Tutto su un solo lato (chiavi e arg aggregazioni)\n",
    "    if not G_s and not A_s:\n",
    "        return \"owner-only\"\n",
    "    if not G_o and not A_o:\n",
    "        return \"server-only\"\n",
    "\n",
    "    # Chiavi da un lato, misure dall'altro (nessuna misura locale)\n",
    "    if not G_s and A_s and not A_o:\n",
    "        return \"server-owner\"  # G su Owner, A su Server\n",
    "    if not G_o and A_o and not A_s:\n",
    "        return \"owner-server\"  # G su Server, A su Owner\n",
    "\n",
    "    # Altrimenti: chiavi spezzate o arg distribuiti\n",
    "    return \"parallel\"\n",
    "\n",
    "\n"
   ],
   "id": "e3a29830daee48a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:58.157133Z",
     "start_time": "2025-09-05T16:18:58.154681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def render_aggs_sql(aggs: List[Dict[str, Any]], Fo: Set[str]) -> str:\n",
    "    exprs = []\n",
    "    for a in aggs:\n",
    "        func = a[\"func\"].upper()\n",
    "        distinct = \"DISTINCT \" if a.get(\"distinct\") else \"\"\n",
    "        arg = a.get(\"arg\")\n",
    "        if arg is None:\n",
    "            expr = f\"{func}(*)\"\n",
    "            alias = a.get(\"alias\") or f\"{func.lower()}_all\"\n",
    "        else:\n",
    "            qual = \"o\" if arg in Fo else \"s\"\n",
    "            expr = f\"{func}({distinct}{qual}.{arg})\"\n",
    "            alias = a.get(\"alias\") or f\"{func.lower()}_{arg}\"\n",
    "        exprs.append(f\"{expr} AS {alias}\")\n",
    "    return \", \".join(exprs)\n"
   ],
   "id": "a1a5e242511f74a8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:35:41.327194Z",
     "start_time": "2025-09-05T16:35:41.321226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def render_having_sql(having: str,\n",
    "                      Fo: Set[str],\n",
    "                      Fs: Set[str],\n",
    "                      group_by: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    Qualifica gli identificatori nella clausola HAVING:\n",
    "    - Argomenti delle funzioni di aggregazione (count/sum/avg/min/max)\n",
    "    - Colonne plain del GROUP BY eventualmente usate nel HAVING\n",
    "    Non tocca gli alias di SELECT (Postgres non li permette in HAVING).\n",
    "    \"\"\"\n",
    "    if not having:\n",
    "        return having\n",
    "\n",
    "    txt = having\n",
    "\n",
    "    # 1) Qualifica gli argomenti delle funzioni di aggregazione\n",
    "    agg_pat = re.compile(\n",
    "        r'(?P<func>count|sum|avg|min|max)\\s*\\(\\s*(?P<distinct>distinct\\s+)?(?P<arg>\\*|[a-zA-Z_][\\w\\.]*)\\s*\\)',\n",
    "        flags=re.I\n",
    "    )\n",
    "\n",
    "    def _qualify_arg(arg: str) -> str:\n",
    "        if arg == '*' or '.' in arg:\n",
    "            return arg  # già qualificato o * → lascio\n",
    "        a = arg.lower()\n",
    "        if a in Fo:\n",
    "            return f\"o.{a}\"\n",
    "        if a in Fs:\n",
    "            return f\"s.{a}\"\n",
    "        # Non appartiene a Fo/Fs: lascio com'è (potrebbe essere literal/param)\n",
    "        return arg\n",
    "\n",
    "    def _agg_repl(m: re.Match) -> str:\n",
    "        func = m.group('func')\n",
    "        distinct = m.group('distinct') or ''\n",
    "        arg = m.group('arg')\n",
    "        qarg = _qualify_arg(arg)\n",
    "        return f\"{func.upper()}({distinct}{qarg})\"\n",
    "\n",
    "    txt = agg_pat.sub(_agg_repl, txt)\n",
    "\n",
    "    # 2) Qualifica eventuali riferimenti \"plain\" a colonne di GROUP BY nel HAVING\n",
    "    # Evitiamo di toccare ciò che è già qualificato (ha un punto) o parole chiave/funzioni.\n",
    "    # Sostituiamo solo token che sono ESATTAMENTE colonne del group_by.\n",
    "    gb_lower = {c.lower() for c in group_by}\n",
    "    keywords = {\"and\",\"or\",\"not\",\"null\",\"is\",\"between\",\"in\",\"like\",\"ilike\",\"similar\",\"escape\",\n",
    "                \"true\",\"false\",\"case\",\"when\",\"then\",\"else\",\"end\",\"exists\",\"all\",\"any\",\"some\"}\n",
    "    func_names = {\"count\",\"sum\",\"avg\",\"min\",\"max\",\"distinct\"}\n",
    "\n",
    "    # token matcher semplice (non dentro stringhe/quoted identifiers)\n",
    "    tok_pat = re.compile(r'\\b([a-zA-Z_][\\w]*)\\b')\n",
    "\n",
    "    def _tok_repl(m: re.Match) -> str:\n",
    "        t = m.group(1)\n",
    "        tl = t.lower()\n",
    "        if tl in keywords or tl in func_names:\n",
    "            return t\n",
    "        if tl in gb_lower:\n",
    "            if tl in Fo:\n",
    "                return f\"o.{tl}\"\n",
    "            if tl in Fs:\n",
    "                return f\"s.{tl}\"\n",
    "        return t\n",
    "\n",
    "    txt = tok_pat.sub(_tok_repl, txt)\n",
    "\n",
    "    return txt\n"
   ],
   "id": "fa13d3cb1c576cf6",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:37:06.706686Z",
     "start_time": "2025-09-05T16:37:06.696251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_subqueries_gb(\n",
    "    select_plain: Set[str], group_by: Set[str], aggs: List[Dict[str, Any]],\n",
    "    Fo: Set[str], Fs: Set[str], strategy: str,\n",
    "    having_clause: str | None = None\n",
    ") -> Tuple[str | None, str | None, str | None]:\n",
    "\n",
    "    # campi necessari lato Server/Owner: select/plain + group_by + argomenti agg\n",
    "    sel_plain = {c.lower() for c in select_plain}\n",
    "    gb = {c.lower() for c in group_by}\n",
    "    agg_args = {a[\"arg\"] for a in aggs if a.get(\"arg\")}\n",
    "\n",
    "    need_fs = ((sel_plain | gb | agg_args) & Fs) - {'id'}\n",
    "    need_fo = ((sel_plain | gb | agg_args) & Fo) - {'id'}\n",
    "\n",
    "    Aqs = sorted(need_fs)\n",
    "    Aqo = sorted(need_fo)\n",
    "\n",
    "    gb_owner = [f\"o.{c}\" for c in sorted(gb & Fo)]\n",
    "    gb_server = [f\"s.{c}\" for c in sorted(gb & Fs)]\n",
    "    gb_all = gb_owner + gb_server\n",
    "    gb_sql = \", \".join(gb_all)\n",
    "\n",
    "    aggs_sql = render_aggs_sql(aggs, Fo)  # usa solo Fo; se vuoi robustezza, vedi nota precedente\n",
    "    select_parts = []\n",
    "    if gb_sql:\n",
    "        select_parts.append(gb_sql)\n",
    "    if aggs_sql:\n",
    "        select_parts.append(aggs_sql)\n",
    "    final_select = \", \".join(select_parts) if select_parts else aggs_sql\n",
    "\n",
    "    qs = qo = qso = None\n",
    "\n",
    "    rendered_having = render_having_sql(having_clause, Fo, Fs, group_by) if having_clause else None\n",
    "\n",
    "\n",
    "    if strategy == \"server-owner\":\n",
    "        # 1) estraggo dal Server le colonne necessarie (id + Fs), senza WHERE\n",
    "        proj_qs = \", \".join([\"s.id\"] + [f\"s.{c}\" for c in Aqs]) if Aqs else \"s.id\"\n",
    "        qs = f\"SELECT {proj_qs} FROM server.patients_server s\"\n",
    "\n",
    "        # 2) aggrego sull'Owner unendo Rs (id, colonne Fs necessarie)\n",
    "        qso = f\"SELECT {final_select} FROM owner.patients_owner o JOIN Rs s USING (id)\"\n",
    "        if gb_sql:\n",
    "            qso += f\" GROUP BY {gb_sql}\"\n",
    "        if having_clause:\n",
    "            qso += f\" HAVING {rendered_having}\"\n",
    "\n",
    "    elif strategy == \"owner-server\":\n",
    "        # 1) creo Ro di soli id\n",
    "        qo = \"SELECT o.id FROM owner.patients_owner o\"\n",
    "\n",
    "        # 2) dal Server prendo (id + Fs necessarie) vincolando a Ro\n",
    "        proj_qs = \", \".join([\"s.id\"] + [f\"s.{c}\" for c in Aqs]) if Aqs else \"s.id\"\n",
    "        qs = f\"SELECT {proj_qs} FROM server.patients_server s JOIN Ro r USING (id)\"\n",
    "\n",
    "        # 3) aggrego sull'Owner unendo Rs\n",
    "        qso = f\"SELECT {final_select} FROM owner.patients_owner o JOIN Rs s USING (id)\"\n",
    "        if gb_sql:\n",
    "            qso += f\" GROUP BY {gb_sql}\"\n",
    "        if having_clause:\n",
    "            qso += f\" HAVING {rendered_having}\"\n",
    "\n",
    "    elif strategy == \"owner-only\":\n",
    "        # se nel SELECT/GROUP BY/AGG servono colonne Fs, devo passare dal Server\n",
    "        needs_server = bool(((sel_plain | gb | agg_args) & Fs))\n",
    "        if needs_server:\n",
    "            qo = \"SELECT o.id FROM owner.patients_owner o\"\n",
    "            proj_qs = \", \".join([\"s.id\"] + [f\"s.{c}\" for c in Aqs]) if Aqs else \"s.id\"\n",
    "            qs = f\"SELECT {proj_qs} FROM server.patients_server s JOIN Ro r USING (id)\"\n",
    "            qso = f\"SELECT {final_select} FROM owner.patients_owner o JOIN Rs s USING (id)\"\n",
    "            if gb_sql:\n",
    "                qso += f\" GROUP BY {gb_sql}\"\n",
    "            if having_clause:\n",
    "                qso += f\" HAVING {rendered_having}\"\n",
    "        else:\n",
    "            # tutto su Owner\n",
    "            qso = f\"SELECT {final_select} FROM owner.patients_owner o\"\n",
    "            if gb_sql:\n",
    "                qso += f\" GROUP BY {gb_sql}\"\n",
    "            if having_clause:\n",
    "                qso += f\" HAVING {rendered_having}\"\n",
    "\n",
    "    elif strategy == \"server-only\":\n",
    "        # se servono colonne Fo devo passare dall'Owner, altrimenti tutto Server\n",
    "        needs_owner = bool(((sel_plain | gb | agg_args) & Fo))\n",
    "        if needs_owner:\n",
    "            proj_qs = \", \".join([\"s.id\"] + [f\"s.{c}\" for c in Aqs]) if Aqs else \"s.id\"\n",
    "            qs = f\"SELECT {proj_qs} FROM server.patients_server s\"\n",
    "            qso = f\"SELECT {final_select} FROM owner.patients_owner o JOIN Rs s USING (id)\"\n",
    "            if gb_sql:\n",
    "                qso += f\" GROUP BY {gb_sql}\"\n",
    "            if having_clause:\n",
    "                qso += f\" HAVING {rendered_having}\"\n",
    "        else:\n",
    "            # tutto su Server\n",
    "            gb_only_s = \", \".join([f\"s.{c}\" for c in sorted(gb & Fs)])\n",
    "            aggs_sql_s = render_aggs_sql(aggs, Fo)\n",
    "            parts = []\n",
    "            if gb_only_s:\n",
    "                parts.append(gb_only_s)\n",
    "            if aggs_sql_s:\n",
    "                parts.append(aggs_sql_s)\n",
    "            final_s = \", \".join(parts) if parts else aggs_sql_s\n",
    "            qso = f\"SELECT {final_s} FROM server.patients_server s\"\n",
    "            if gb_only_s:\n",
    "                qso += f\" GROUP BY {gb_only_s}\"\n",
    "            if having_clause:\n",
    "                qso += f\" HAVING {rendered_having}\"\n",
    "\n",
    "    elif strategy == \"parallel\":\n",
    "        # Materializza entrambi i lati con i soli attributi necessari, poi aggrega su Owner\n",
    "        # Ro: id + colonne Fo necessarie\n",
    "        proj_qo = \", \".join([\"o.id\"] + [f\"o.{c}\" for c in Aqo]) if Aqo else \"o.id\"\n",
    "        qo = f\"SELECT {proj_qo} FROM owner.patients_owner o\"\n",
    "\n",
    "        # Rs: id + colonne Fs necessarie\n",
    "        proj_qs = \", \".join([\"s.id\"] + [f\"s.{c}\" for c in Aqs]) if Aqs else \"s.id\"\n",
    "        qs = f\"SELECT {proj_qs} FROM server.patients_server s\"\n",
    "\n",
    "        # Aggregazione finale su Owner unendo Ro e Rs (e mantenendo alias o/s)\n",
    "        qso = (\n",
    "            \"SELECT \" + final_select +\n",
    "            \" FROM owner.patients_owner o\"\n",
    "            \" JOIN Ro r USING (id)\"\n",
    "            \" JOIN Rs s USING (id)\"\n",
    "        )\n",
    "        if gb_sql:\n",
    "            qso += f\" GROUP BY {gb_sql}\"\n",
    "        if having_clause:\n",
    "            qso += f\" HAVING {rendered_having}\"\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Strategy must be one of: server-owner, owner-server, owner-only, server-only, parallel\")\n",
    "\n",
    "    return qs, qo, qso\n"
   ],
   "id": "e04bba1ccb2f8703",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:58.461954Z",
     "start_time": "2025-09-05T16:18:58.459379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_query_gb(query: str, Fo: Set[str], Fs: Set[str]) -> Dict[str, any]:\n",
    "    # Parse per GROUP BY con (opzionale) HAVING, senza WHERE\n",
    "    select_plain, group_by, aggs, having_clause = parse_query_groupby(query)\n",
    "\n",
    "    # Classificazione: chiavi e argomenti delle agg su Fo / Fs\n",
    "    classified_gb = classify_groupby_agg(group_by, aggs, Fo, Fs)\n",
    "\n",
    "    # Scelta strategia (HAVING non influisce sulla scelta)\n",
    "    strategy_key = choose_strategy_groupby(classified_gb)\n",
    "    strategy_eff = strategy_key\n",
    "\n",
    "    # Subquery (passiamo anche la HAVING alla finale)\n",
    "    qs, qo, qso = generate_subqueries_gb(\n",
    "        select_plain=select_plain,\n",
    "        group_by=group_by,\n",
    "        aggs=aggs,\n",
    "        Fo=Fo,\n",
    "        Fs=Fs,\n",
    "        strategy=strategy_eff,\n",
    "        having_clause=having_clause\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Query\": query,\n",
    "        \"SELECT_PLAIN\": select_plain,\n",
    "        \"GROUP_BY\": group_by,\n",
    "        \"AGGS\": aggs,\n",
    "        \"HAVING\": having_clause,\n",
    "        \"Classificazione_GB\": classified_gb,\n",
    "        \"Strategia\": strategy_key,\n",
    "        \"Strategia_eff\": strategy_eff,\n",
    "        \"qs\": qs, \"qo\": qo, \"qso\": qso\n",
    "    }\n"
   ],
   "id": "a811ec717e2928d9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:58.604471Z",
     "start_time": "2025-09-05T16:18:58.601872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _replan_alternative_gb(plan: dict, Fo: set, Fs: set) -> dict | None:\n",
    "    # Flip tra owner-server e server-owner. Se non è uno dei due, niente alternativa.\n",
    "    cur = plan.get(\"Strategia_eff\") or plan.get(\"Strategia\")\n",
    "    alt = {\"owner-server\": \"server-owner\", \"server-owner\": \"owner-server\"}.get(cur)\n",
    "    if not alt:\n",
    "        return None\n",
    "\n",
    "    # Rigenera le subquery per l'alternativa usando anche HAVING (se presente)\n",
    "    qs, qo, qso = generate_subqueries_gb(\n",
    "        select_plain=plan[\"SELECT_PLAIN\"],\n",
    "        group_by=plan[\"GROUP_BY\"],\n",
    "        aggs=plan[\"AGGS\"],\n",
    "        Fo=Fo, Fs=Fs, strategy=alt,\n",
    "        having_clause=plan.get(\"HAVING\")  # <— aggiunto\n",
    "    )\n",
    "    return {\"Strategia\": alt, \"qs\": qs, \"qo\": qo, \"qso\": qso}\n"
   ],
   "id": "fdb0708ae317afcd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:58.735265Z",
     "start_time": "2025-09-05T16:18:58.720926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_query_gb(query: str,\n",
    "                      Fo: set, Fs: set,\n",
    "                      tag: str | None = None,\n",
    "                      schema: str = \"work\",\n",
    "                      save_to: str | None = None,\n",
    "                      also_compare_alt: bool = True) -> dict:\n",
    "    plan = process_query_gb(query, Fo, Fs)\n",
    "\n",
    "    # per il caso 3 usiamo la strategia effettiva (coerente con process_query_gb)\n",
    "    sk = plan.get(\"Strategia_eff\") or plan[\"Strategia\"]\n",
    "\n",
    "    tag = tag or uuid.uuid4().hex[:8]\n",
    "\n",
    "    run(f\"CREATE SCHEMA IF NOT EXISTS {schema};\")\n",
    "    ro_name, rs_name, out_name = f\"{schema}.ro_{tag}\", f\"{schema}.rs_{tag}\", f\"{schema}.out_{tag}\"\n",
    "\n",
    "    counts, sizes = {}, {}\n",
    "\n",
    "    if sk == \"owner-server\":\n",
    "        qo = _strip_semicolon(plan[\"qo\"])\n",
    "        qs = _strip_semicolon(plan[\"qs\"])\n",
    "        qso = _strip_semicolon(plan[\"qso\"])\n",
    "\n",
    "        run(f\"DROP TABLE IF EXISTS {ro_name}; CREATE TABLE {ro_name} AS {qo};\")\n",
    "        counts[\"ro\"], sizes[\"ro\"] = _count_table(ro_name), _size_table(ro_name)\n",
    "\n",
    "        qs_mat = qs.replace(\" Ro \", f\" {ro_name} \")\n",
    "        run(f\"DROP TABLE IF EXISTS {rs_name}; CREATE TABLE {rs_name} AS {qs_mat};\")\n",
    "        counts[\"rs\"], sizes[\"rs\"] = _count_table(rs_name), _size_table(rs_name)\n",
    "\n",
    "        qso_mat = qso.replace(\" Rs \", f\" {rs_name} \")\n",
    "        run(f\"DROP TABLE IF EXISTS {out_name}; CREATE TABLE {out_name} AS {qso_mat};\")\n",
    "        counts[\"out\"], sizes[\"out\"] = _count_table(out_name), _size_table(out_name)\n",
    "\n",
    "    elif sk == \"server-owner\":\n",
    "        qs = _strip_semicolon(plan[\"qs\"])\n",
    "        qso = _strip_semicolon(plan[\"qso\"])\n",
    "\n",
    "        run(f\"DROP TABLE IF EXISTS {rs_name}; CREATE TABLE {rs_name} AS {qs};\")\n",
    "        counts[\"rs\"], sizes[\"rs\"] = _count_table(rs_name), _size_table(rs_name)\n",
    "\n",
    "        qso_mat = qso.replace(\" Rs \", f\" {rs_name} \")\n",
    "        run(f\"DROP TABLE IF EXISTS {out_name}; CREATE TABLE {out_name} AS {qso_mat};\")\n",
    "        counts[\"out\"], sizes[\"out\"] = _count_table(out_name), _size_table(out_name)\n",
    "\n",
    "    elif sk in (\"owner-only\", \"server-only\"):\n",
    "\n",
    "        if plan[\"qo\"]:\n",
    "            qo = _strip_semicolon(plan[\"qo\"])\n",
    "            run(f\"DROP TABLE IF EXISTS {ro_name}; CREATE TABLE {ro_name} AS {qo};\")\n",
    "            counts[\"ro\"], sizes[\"ro\"] = _count_table(ro_name), _size_table(ro_name)\n",
    "\n",
    "        if plan[\"qs\"]:\n",
    "            qs = _strip_semicolon(plan[\"qs\"])\n",
    "            qs_mat = qs.replace(\" Ro \", f\" {ro_name} \") if plan[\"qo\"] else qs\n",
    "            run(f\"DROP TABLE IF EXISTS {rs_name}; CREATE TABLE {rs_name} AS {qs_mat};\")\n",
    "            counts[\"rs\"], sizes[\"rs\"] = _count_table(rs_name), _size_table(rs_name)\n",
    "\n",
    "        qso = _strip_semicolon(plan[\"qso\"])\n",
    "        qso_mat = qso.replace(\" Rs \", f\" {rs_name} \") if plan[\"qs\"] else qso\n",
    "        run(f\"DROP TABLE IF EXISTS {out_name}; CREATE TABLE {out_name} AS {qso_mat};\")\n",
    "        counts[\"out\"], sizes[\"out\"] = _count_table(out_name), _size_table(out_name)\n",
    "\n",
    "    elif sk == \"parallel\":\n",
    "        # materializza entrambi i lati, poi la query finale che li usa entrambi\n",
    "        qo = _strip_semicolon(plan[\"qo\"])\n",
    "        qs = _strip_semicolon(plan[\"qs\"])\n",
    "        qso = _strip_semicolon(plan[\"qso\"])\n",
    "\n",
    "        run(f\"DROP TABLE IF EXISTS {ro_name}; CREATE TABLE {ro_name} AS {qo};\")\n",
    "        counts[\"ro\"], sizes[\"ro\"] = _count_table(ro_name), _size_table(ro_name)\n",
    "\n",
    "        run(f\"DROP TABLE IF EXISTS {rs_name}; CREATE TABLE {rs_name} AS {qs};\")\n",
    "        counts[\"rs\"], sizes[\"rs\"] = _count_table(rs_name), _size_table(rs_name)\n",
    "\n",
    "        qso_mat = (\n",
    "            qso.replace(\" Ro \", f\" {ro_name} \")\n",
    "               .replace(\" Rs \", f\" {rs_name} \")\n",
    "        )\n",
    "        run(f\"DROP TABLE IF EXISTS {out_name}; CREATE TABLE {out_name} AS {qso_mat};\")\n",
    "        counts[\"out\"], sizes[\"out\"] = _count_table(out_name), _size_table(out_name)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Strategia sconosciuta: {sk!r}\")\n",
    "\n",
    "    net_bytes = _network_bytes(sk, sizes)\n",
    "\n",
    "    alt_info = None\n",
    "    if also_compare_alt and sk in (\"owner-server\", \"server-owner\"):\n",
    "        alt = _replan_alternative_gb(plan, Fo, Fs)\n",
    "        if alt:\n",
    "            tag_alt = tag + \"_alt\"\n",
    "            ro_alt, rs_alt, out_alt = f\"{schema}.ro_{tag_alt}\", f\"{schema}.rs_{tag_alt}\", f\"{schema}.out_{tag_alt}\"\n",
    "            sizes_alt = {}\n",
    "\n",
    "            if alt[\"Strategia\"] == \"owner-server\":\n",
    "                qo_alt = _strip_semicolon(alt[\"qo\"])\n",
    "                qs_alt = _strip_semicolon(alt[\"qs\"])\n",
    "                qso_alt = _strip_semicolon(alt[\"qso\"])\n",
    "\n",
    "                run(f\"DROP TABLE IF EXISTS {ro_alt}; CREATE TABLE {ro_alt} AS {qo_alt};\")\n",
    "                sizes_alt[\"ro\"] = _size_table(ro_alt)\n",
    "\n",
    "                qs_alt_mat = qs_alt.replace(\" Ro \", f\" {ro_alt} \")\n",
    "                run(f\"DROP TABLE IF EXISTS {rs_alt}; CREATE TABLE {rs_alt} AS {qs_alt_mat};\")\n",
    "                sizes_alt[\"rs\"] = _size_table(rs_alt)\n",
    "\n",
    "                qso_alt_mat = qso_alt.replace(\" Rs \", f\" {rs_alt} \")\n",
    "                run(f\"DROP TABLE IF EXISTS {out_alt}; CREATE TABLE {out_alt} AS {qso_alt_mat};\")\n",
    "\n",
    "            else:  # server-owner\n",
    "                qs_alt = _strip_semicolon(alt[\"qs\"])\n",
    "                qso_alt = _strip_semicolon(alt[\"qso\"])\n",
    "                run(f\"DROP TABLE IF EXISTS {rs_alt}; CREATE TABLE {rs_alt} AS {qs_alt};\")\n",
    "                sizes_alt[\"rs\"] = _size_table(rs_alt)\n",
    "                qso_alt_mat = qso_alt.replace(\" Rs \", f\" {rs_alt} \")\n",
    "                run(f\"DROP TABLE IF EXISTS {out_alt}; CREATE TABLE {out_alt} AS {qso_alt_mat};\")\n",
    "\n",
    "            net_alt = _network_bytes(alt[\"Strategia\"], sizes_alt)\n",
    "            saving_pct = 1 - (net_bytes / net_alt) if net_alt and net_alt > 0 else None\n",
    "            alt_info = {\n",
    "                \"alt_strategy\": alt[\"Strategia\"],\n",
    "                \"alt_network_bytes\": net_alt,\n",
    "                \"saving_pct\": float(saving_pct) if saving_pct is not None else None,\n",
    "                \"tables_alt\": {\"ro\": ro_alt if \"ro\" in sizes_alt else None,\n",
    "                               \"rs\": rs_alt if \"rs\" in sizes_alt else None,\n",
    "                               \"out\": out_alt}\n",
    "            }\n",
    "\n",
    "    row = {\n",
    "        \"tag\": tag,\n",
    "        \"query\": plan[\"Query\"],\n",
    "        \"strategy\": sk,\n",
    "        \"result_owner\": counts.get(\"ro\"), \"result_server\": counts.get(\"rs\"), \"result_out\": counts.get(\"out\"),\n",
    "        \"bytes_result_owner\": sizes.get(\"ro\"), \"bytes_result_server\": sizes.get(\"rs\"),\n",
    "        \"bytes_result_out\": sizes.get(\"out\"),\n",
    "        \"network_bytes\": net_bytes,\n",
    "        \"alt_strategy\": alt_info[\"alt_strategy\"] if alt_info else None,\n",
    "        \"alt_network_bytes\": alt_info[\"alt_network_bytes\"] if alt_info else None,\n",
    "        \"saving_pct\": alt_info[\"saving_pct\"] if alt_info else None\n",
    "    }\n",
    "\n",
    "    if save_to:\n",
    "        save_to = os.path.abspath(save_to)\n",
    "        df = pd.DataFrame([row])\n",
    "        header = not os.path.exists(save_to)\n",
    "        df.to_csv(save_to, mode=\"a\", index=False, header=header)\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan,\n",
    "        \"row\": row,\n",
    "        \"tables\": {\"result_owner\": ro_name if \"ro\" in counts else None,\n",
    "                   \"result_server\": rs_name if \"rs\" in counts else None,\n",
    "                   \"result_out\": out_name if \"out\" in counts else None},\n",
    "        \"alt\": alt_info\n",
    "    }\n"
   ],
   "id": "a82342cff1f51817",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:18:45.930958Z",
     "start_time": "2025-09-05T16:18:45.928011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_queries_gb(queries: list[str],\n",
    "                        Fo: set, Fs: set,\n",
    "                        schema: str = \"work\",\n",
    "                        save_to: str | None = None,\n",
    "                        also_compare_alt: bool = True) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for i, q in enumerate(queries, 1):\n",
    "        tag = f\"hv{i:02d}\"\n",
    "        res = evaluate_query_gb(q, Fo, Fs, tag=tag, schema=schema,\n",
    "                                save_to=save_to, also_compare_alt=also_compare_alt)\n",
    "        rows.append(res[\"row\"])\n",
    "    return pd.DataFrame(rows)"
   ],
   "id": "f5e60b431ef7a69e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TESTING",
   "id": "fb97890b3ef3f351"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:37:12.414445Z",
     "start_time": "2025-09-05T16:37:12.390297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q = \"\"\"\n",
    "SELECT city, MAX(income) AS max_inc, AVG(healthcare_coverage) AS avg_cov\n",
    "FROM patients\n",
    "GROUP BY city\n",
    "HAVING AVG(healthcare_coverage) >= 500000 AND MAX(income) >= 900000;\n",
    "\"\"\"\n",
    "\n",
    "res = evaluate_query_gb(q, Fo, Fs, tag='q01')\n",
    "print(res)\n"
   ],
   "id": "b09afd250979a9c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': {'Query': '\\nSELECT city, MAX(income) AS max_inc, AVG(healthcare_coverage) AS avg_cov\\nFROM patients\\nGROUP BY city\\nHAVING AVG(healthcare_coverage) >= 500000 AND MAX(income) >= 900000;\\n', 'SELECT_PLAIN': {'city'}, 'GROUP_BY': {'city'}, 'AGGS': [{'func': 'max', 'arg': 'income', 'distinct': False, 'alias': 'max_inc'}, {'func': 'avg', 'arg': 'healthcare_coverage', 'distinct': False, 'alias': 'avg_cov'}], 'HAVING': 'AVG(healthcare_coverage) >= 500000 AND MAX(income) >= 900000', 'Classificazione_GB': {'G_owner': {'city'}, 'G_server': set(), 'Agg_owner': {'income'}, 'Agg_server': {'healthcare_coverage'}}, 'Strategia': 'parallel', 'Strategia_eff': 'parallel', 'qs': 'SELECT s.id, s.healthcare_coverage FROM server.patients_server s', 'qo': 'SELECT o.id, o.city, o.income FROM owner.patients_owner o', 'qso': 'SELECT o.city, MAX(o.income) AS max_inc, AVG(s.healthcare_coverage) AS avg_cov FROM owner.patients_owner o JOIN Ro r USING (id) JOIN Rs s USING (id) GROUP BY o.city HAVING AVG(s.healthcare_coverage) >= 500000 AND MAX(o.income) >= 900000'}, 'row': {'tag': 'q01', 'query': '\\nSELECT city, MAX(income) AS max_inc, AVG(healthcare_coverage) AS avg_cov\\nFROM patients\\nGROUP BY city\\nHAVING AVG(healthcare_coverage) >= 500000 AND MAX(income) >= 900000;\\n', 'strategy': 'parallel', 'result_owner': 112, 'result_server': 112, 'result_out': 1, 'bytes_result_owner': 24576, 'bytes_result_server': 24576, 'bytes_result_out': 16384, 'network_bytes': 49152, 'alt_strategy': None, 'alt_network_bytes': None, 'saving_pct': None}, 'tables': {'result_owner': 'work.ro_q01', 'result_server': 'work.rs_q01', 'result_out': 'work.out_q01'}, 'alt': None}\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:37:43.812154Z",
     "start_time": "2025-09-05T16:37:43.798154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if res[\"tables\"][\"result_owner\"]:\n",
    "    print(\"ro\")\n",
    "    run(f\"SELECT * FROM {res['tables']['result_owner']} ;\", show=True)  # Ro (Qo)\n",
    "if res[\"tables\"][\"result_server\"]:\n",
    "    print(\"rs\")\n",
    "    run(f\"SELECT * FROM {res['tables']['result_server']} ;\", show=True)  # Rs (Qs)\n",
    "print(\"rout\")\n",
    "run(f\"SELECT * FROM {res['tables']['result_out']};\")  # Out (Qso)"
   ],
   "id": "915f7b7ef9730cf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                       id             city     income\n",
       "0    c10e497b-ed25-d6c6-e043-144724bf84da         Stoneham  130194.00\n",
       "1    08c1e3c5-4732-9008-ddd4-edc1f2358521         Amesbury    7176.00\n",
       "2    ac5294eb-05dc-ed5b-2e7c-021eebd1c7b3           Quincy   13147.00\n",
       "3    aeabefce-854a-81f8-2a92-134a22ae6871          Amherst   66739.00\n",
       "4    a514d082-312d-f9cf-6e1b-42b6fa1bfb6f        Billerica  941064.00\n",
       "..                                    ...              ...        ...\n",
       "107  f15015b7-a177-da0a-d208-3c63f799da12         Townsend   37328.00\n",
       "108  92057acb-1a4e-921b-8d21-822d52094f47          Amherst  199051.00\n",
       "109  bd38b1a4-d16e-a126-426c-0a4a278d1948          Amherst  199051.00\n",
       "110  80139337-c548-00de-53c3-5cf9aae9af60  Acushnet Center   33707.00\n",
       "111  17cd7e79-0ecb-44f8-e052-d31b128bd938  Acushnet Center   33707.00\n",
       "\n",
       "[112 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>city</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c10e497b-ed25-d6c6-e043-144724bf84da</td>\n",
       "      <td>Stoneham</td>\n",
       "      <td>130194.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08c1e3c5-4732-9008-ddd4-edc1f2358521</td>\n",
       "      <td>Amesbury</td>\n",
       "      <td>7176.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac5294eb-05dc-ed5b-2e7c-021eebd1c7b3</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>13147.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aeabefce-854a-81f8-2a92-134a22ae6871</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>66739.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a514d082-312d-f9cf-6e1b-42b6fa1bfb6f</td>\n",
       "      <td>Billerica</td>\n",
       "      <td>941064.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>f15015b7-a177-da0a-d208-3c63f799da12</td>\n",
       "      <td>Townsend</td>\n",
       "      <td>37328.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>92057acb-1a4e-921b-8d21-822d52094f47</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>199051.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>bd38b1a4-d16e-a126-426c-0a4a278d1948</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>199051.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>80139337-c548-00de-53c3-5cf9aae9af60</td>\n",
       "      <td>Acushnet Center</td>\n",
       "      <td>33707.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>17cd7e79-0ecb-44f8-e052-d31b128bd938</td>\n",
       "      <td>Acushnet Center</td>\n",
       "      <td>33707.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                       id healthcare_coverage\n",
       "0    c10e497b-ed25-d6c6-e043-144724bf84da              591.36\n",
       "1    08c1e3c5-4732-9008-ddd4-edc1f2358521           154001.38\n",
       "2    ac5294eb-05dc-ed5b-2e7c-021eebd1c7b3            91896.98\n",
       "3    aeabefce-854a-81f8-2a92-134a22ae6871             5423.85\n",
       "4    a514d082-312d-f9cf-6e1b-42b6fa1bfb6f          1087558.13\n",
       "..                                    ...                 ...\n",
       "107  f15015b7-a177-da0a-d208-3c63f799da12           188962.42\n",
       "108  92057acb-1a4e-921b-8d21-822d52094f47            82177.38\n",
       "109  bd38b1a4-d16e-a126-426c-0a4a278d1948            82280.07\n",
       "110  80139337-c548-00de-53c3-5cf9aae9af60          1442735.73\n",
       "111  17cd7e79-0ecb-44f8-e052-d31b128bd938           623279.62\n",
       "\n",
       "[112 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>healthcare_coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c10e497b-ed25-d6c6-e043-144724bf84da</td>\n",
       "      <td>591.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08c1e3c5-4732-9008-ddd4-edc1f2358521</td>\n",
       "      <td>154001.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac5294eb-05dc-ed5b-2e7c-021eebd1c7b3</td>\n",
       "      <td>91896.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aeabefce-854a-81f8-2a92-134a22ae6871</td>\n",
       "      <td>5423.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a514d082-312d-f9cf-6e1b-42b6fa1bfb6f</td>\n",
       "      <td>1087558.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>f15015b7-a177-da0a-d208-3c63f799da12</td>\n",
       "      <td>188962.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>92057acb-1a4e-921b-8d21-822d52094f47</td>\n",
       "      <td>82177.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>bd38b1a4-d16e-a126-426c-0a4a278d1948</td>\n",
       "      <td>82280.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>80139337-c548-00de-53c3-5cf9aae9af60</td>\n",
       "      <td>1442735.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>17cd7e79-0ecb-44f8-e052-d31b128bd938</td>\n",
       "      <td>623279.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rout\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        city    max_inc               avg_cov\n",
       "0  Billerica  941064.00  1087558.130000000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>max_inc</th>\n",
       "      <th>avg_cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billerica</td>\n",
       "      <td>941064.00</td>\n",
       "      <td>1087558.130000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "queries = [\n",
    "    \"SELECT city, gender, COUNT(*) AS n, AVG(income) AS avg_inc FROM patients WHERE zip <> '00000' GROUP BY city, gender HAVING COUNT(*) >= 2\",\n",
    "    \"SELECT city, COUNT(*) AS n FROM patients WHERE zip <> '00000' GROUP BY city HAVING COUNT(*) >= 3\",\n",
    "    \"\",\n",
    "]\n",
    "df = evaluate_queries_gb(queries, Fo, Fs save_to='query3_evaluation.cvs')\n",
    "df"
   ],
   "id": "ab8bb9741cfa1dff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
